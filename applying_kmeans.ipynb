{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "770e7132-5295-4bb8-b9ce-f57cc1a7e680",
   "metadata": {},
   "source": [
    "# Applying the *k*-Means Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b774923b",
   "metadata": {},
   "source": [
    "## Review the brief\n",
    "\n",
    "To familiarize ourselves with carrying out cluster analysis using Python, we'll work through an example of applying the k-means algorithm to a 2-dimensional dataset on countries of the world.\n",
    "\n",
    "Our task is to find and group similar countries together on the basis of two features, fertility rate and female labor force participation rate. \n",
    "\n",
    "We'll see how Python can be used to perform a full cluster analysis. As a reminder, the steps to a cluster analysis are: \n",
    "1. Determine if clustering is appropriate for the task \n",
    "2. Pre-process the data\n",
    "3. Carry out the algorithm \n",
    "4. Evaluate the results\n",
    "5. Interpret the results\n",
    "\n",
    "As you work through this notebook, you'll complete 12 tasks. If you get stuck at any point, you can refer to the completed notebook `applying_kmeans_completed.ipynb`, which provides example answers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36ed391-9df3-4d54-b2c1-e1851f658ac1",
   "metadata": {},
   "source": [
    "## Import necessary libraries\n",
    "\n",
    "First, we need to import some important libraries for our analysis. We'll mostly be working with the `sklearn` library. \n",
    "\n",
    "### *Task 1 - import libraries (run cell)*\n",
    "- Run the cell below to import the libraries that we'll be working with. \n",
    "- Take a look at some of the `sklearn` documentation on its clustering functions by clicking [this link](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.cluster)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c76f3a-1e20-4169-9d42-c40c4df6e80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "\n",
    "# for loading and manipulating dataframes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for various plotting functions\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# preprocessing functions to scale our data\n",
    "from sklearn.preprocessing import scale, StandardScaler, normalize\n",
    "\n",
    "# function to carry out k-means\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ed54f5-5ceb-4aa7-b525-9498770f1cc1",
   "metadata": {},
   "source": [
    "## Load in and explore the data\n",
    "\n",
    "To begin, let's load in and explore our dataset. The data is from the 2018 World Bank Development Indicators and features 2 variables - female labor force participation rate and fertility rate. You can look at the data on the World Bank site by clicking [this link](https://databank.worldbank.org/source/world-development-indicators#).\n",
    "\n",
    "### *Task 2 - load data*\n",
    "Read in the `countries.csv` data file that you downloaded into a data frame named `data`. \n",
    "Print out the first 10 rows of the dataset using `.head()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9571768-4365-4c40-a1fe-5a99a6092039",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a72131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the first 10 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56350113",
   "metadata": {},
   "source": [
    "Next, let's inspect the values in our data set. First, let's make sure we have no missing values and that our cluster variables are stored as numeric values. \n",
    "\n",
    "### *Task 3 - data overview*\n",
    "Apply the `.info()` method to our data frame to check our values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3904b119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df5d5cf",
   "metadata": {},
   "source": [
    "We can see the data contains 187 rows representing 187 countries. The data is already clean, since the two variables we are using for clustering are numerical, and there are no missing values. \n",
    "\n",
    "### *Task 4 - summary statistics*\n",
    "Look at some summary statistics for our variables using the `.describe()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fa7992-1969-4615-988a-8967bae8d299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f83333",
   "metadata": {},
   "source": [
    "We can see that the two variables have different scales: female labor force rate ranges from about 8 to 56, whereas fertility rate ranges from around 1 to 7. This is important to note since we want to scale our data before applying our algorithm. \n",
    "\n",
    "Before we do so, let's quickly look at a scatter plot of the two variables to see what our data looks like visually. \n",
    "\n",
    "### *Task 5 - scatter plot*\n",
    "Create a scatter plot of the two variables with the variable `female_labor` on the x-axis and `fertility_rate` on the y-axis using the `sns.scatterplot()` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c57d745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a scatter plot of the 2 variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba162b1",
   "metadata": {},
   "source": [
    "From this scatter plot, there are a few things for us to note: \n",
    "1. There are a few values for each variable that may be considered outliers, but, for now, we're going to keep all the observations for our analysis.\n",
    "2. We can already see that there are a few spots where we might detect a grouping of countries. Although we can't say with certainty how many clusters are going to be best for our analysis, it looks like there might be potentially three groupings: \n",
    "    * Countries with high female labor force participation rates and low fertility rates\n",
    "    * Countries with high female labor force rates and high fertility rates\n",
    "    * Countries with lower female labor rates and a mix of fertility rates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14fe5dc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500eecb5",
   "metadata": {},
   "source": [
    "# Perform a Cluster Analysis\n",
    "Now that we've looked over our dataset, it's time to begin our analysis. \n",
    "## 1. Determine if clustering is appropriate for the task\n",
    "\n",
    "First, we must decide whether or not clustering is suited for our problem. This involves domain knowledge and determining clustering tendency. \n",
    "\n",
    "Before applying any analysis, you should determine that finding similar groups in your data will help answer your questions. In this example, we already know from the brief that our goal is to find similar groups of countries, so clustering will be useful. \n",
    "\n",
    "Additionally, you should check for cluster tendency. As mentioned, there are several metrics to do so, but for this example, we will simply verify this visually. Take a look at our scatter plot of variables again from '*Task 5*' above.\n",
    "\n",
    "As we saw in *Task 5*, there is evidence of grouping in this plot. This helps validate that our data has clustering tendency. However, this is not always possible to see visually in two dimensions. Furthermore, in multiple dimensions, validating cluster tendency can't be done visually and requires the use of domain knowledge and various metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7b493c",
   "metadata": {},
   "source": [
    "## 2. Preprocess the data\n",
    "\n",
    "Now that we have inspected our data, ensured it is clean, and validated that clustering can be used for our problem, it's time to preprocess the data before applying our algorithm. \n",
    "\n",
    "We will **scale** our data so that all variables are of similar magnitude, and, therefore, they will contribute similarly to the clustering. Scaling is an important aspect of many machine learning problems.\n",
    "\n",
    "\n",
    "To scale our data, we will use the `StandardScaler()` from `sklearn`. You can read more about it [here](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html).\n",
    "\n",
    "### *Task  6 - scale data (run cell)*\n",
    "Run the cell below to scale the data. We will store the scaled variables in `data_scaled`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74257e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create scaling object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# scale our variables \n",
    "data_scaled = scaler.fit_transform(data[['female_labor', 'fertility_rate']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81d21cf",
   "metadata": {},
   "source": [
    "## 3. Carry out the algorithm\n",
    "Our data is ready for clustering. The next step is to run the *k*-means algorithm on our scaled data using the `KMeans()` function from `sklearn`. Make sure to read about the function and its parameters from the documentation by clicking [this link](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html).\n",
    "\n",
    "There are two steps to carry out k-means using `KMeans()`: \n",
    "1. Instantiate a model with parameter values.\n",
    "    * The number of clusters *k* is given by the argument `n_clusters`. In this analysis, we've chosen to identify 3 clusters, since from exploring the scatter plot of the data we estimated there was a potential for 3 groupings. \n",
    "    * In addition, we often set the parameter for the random state, `random_state`. This ensures that each time we run our code, the algorithm uses the same initial conditions. For k-means, this means that when we use the same `n_clusters`, the data points are assigned to the same final cluster each time. \n",
    "    \n",
    "    In this analysis, we set the random state to 123, although this could be any number. Inputting the same value each time for the random state (whether that value is 123 or a different one), ensures our analysis uses the same initial conditions.  \n",
    "\n",
    "  \n",
    "2. Fit the model to the data using `.fit()` method. This action computes the k-means clustering.\n",
    "\n",
    "### *Task 7 - apply k-means (run cells)*\n",
    "Run the four cells below to apply k-means to our scaled data, assign the cluster labels to our dataframe, and visualize our clusters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d9078d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a model with parameter values \n",
    "model = KMeans(n_clusters=3, random_state=123)\n",
    "\n",
    "# run .fit() to fit the model to the (scaled) data\n",
    "model.fit(data_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941dde5b",
   "metadata": {},
   "source": [
    "After running our model, we can access the cluster labels that the algorithm assigned to each data point through the \n",
    "model's attribute `.labels_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7c240e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# access the clustering results via .labels_ after running .fit()\n",
    "model.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d16aeb",
   "metadata": {},
   "source": [
    "Now let's add the cluster labels to the original data frame to analyze our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67add8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the cluster labels to the original dataframe\n",
    "data['cluster'] = model.labels_\n",
    "\n",
    "# inspect the new cluster column\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e23cac",
   "metadata": {},
   "source": [
    "Now that we have our cluster labels, we can graph our scatter plot again, but now with the data points colored by their cluster membership."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a6a7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise the clusters by replotting our scatter plot \n",
    "# but now with cluster label as color\n",
    "sns.scatterplot(x=data['female_labor'],\n",
    "                y=data['fertility_rate'],\n",
    "                hue=data['cluster'],\n",
    "                palette='Dark2_r',\n",
    "                legend = 'full')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bd95d6",
   "metadata": {},
   "source": [
    "This looks like we found fairly sensible clusters, which we identified visually earlier. We can observe: \n",
    "\n",
    "- Cluster 0 has strong cluster cohesion and contains countries with high female labor force partition rates and low fertility rates.\n",
    "- Cluster 1 is more dispersed, but generally includes countries with generally high female labor force rates and high fertility rates.\n",
    "- Finally, Cluster 2 is the most sparse cluster and contains countries with lower female labor force rates and generally low fertility rates, with the exception of a few countries with higher fertility rates.\n",
    "\n",
    "Take a moment to think about what this means about the relationship between these two variables and among the clusters. Were any results surprising?\n",
    "\n",
    "Before we interpret further and take a closer look at the countries within each cluster, let's first:\n",
    "- Understand the need for scaling\n",
    "- Evaluate our clusters and validate our choice for *k*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96d31a3",
   "metadata": {},
   "source": [
    "### Note: What if we hadn't scaled our data?\n",
    "\n",
    "Remember that if we don't scale our data before clustering, variables with larger scales can have a disproportionate effect on the clusters. We can illustrate the effect of scaling by copying the code we used to cluster above, but this time performing it on the unscaled data.\n",
    "\n",
    "### *Task 8 - non-scaled data (run cell)*\n",
    "Run the cell below to apply k-means on our unscaled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82bbe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset the non-scaled variables \n",
    "data_not_scaled = data[['female_labor', 'fertility_rate']]\n",
    "\n",
    "# instantiate a model with the same parameter values \n",
    "model2 = KMeans(n_clusters=3, random_state=123)\n",
    "\n",
    "# run .fit() to fit the model to the (non-scaled) data\n",
    "model2.fit(data_not_scaled)\n",
    "\n",
    "# add the cluster labels to the data frame \n",
    "data['cluster_not_scaled'] = model2.labels_\n",
    "\n",
    "# visualise the clusters by replotting our scatter plot \n",
    "# with cluster label as color\n",
    "sns.scatterplot(x=data['female_labor'],\n",
    "                y=data['fertility_rate'],\n",
    "                hue=data['cluster_not_scaled'],\n",
    "                palette='Dark2_r',\n",
    "                legend = 'full')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec27036",
   "metadata": {},
   "source": [
    "Notice how when we apply clustering to non-scaled data, the clusters turn out in stripes rather than our intuitive findings above. This is because the variable with the larger scale, female labor force rate, dominates how the clusters are determined. The variable overpowers any influence of the other variable, fertility rate, simply because its values are on a larger scale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a14977",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f07d843",
   "metadata": {},
   "source": [
    "<h1><center>BREAK</center></h1>\n",
    "<center> The remainder of this notebook covers how we evaluate and interpret the results of our analysis. </center>\n",
    "<center>Return to the introduction and complete the relevant sections before completing the rest of the notebook. If you close the notebook beforehand, remember to run all cells above before working in the cells below. </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4deb810b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2673f49",
   "metadata": {},
   "source": [
    "## 4. Evaluate the results\n",
    "Now that we have produced our clustering, remember the next step is to ask questions such as: are our results \"good\"? How can we quantify this? Did we pick the best value of k? \n",
    "\n",
    "We can use **inertia** to help us evaluate cluster cohesion, which is one aspect of a \"good\" clustering.\n",
    "### *Task 9 - inspect inertia (run cell)*\n",
    "We can see the calculated inertia score using the `.inertia_` attribute.  \n",
    "Run the cell below to inspect the inertia score from the analysis above.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a43d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at inertia score \n",
    "model.inertia_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095dadc5",
   "metadata": {},
   "source": [
    "From this, we know that inertia (or WCSS) - the total squared distances from each point to its cluster center - is around 94. On its own, we can't draw many conclusions from the score. \n",
    "\n",
    "However, we can run our algorithm on the dataset multiple times at different parameter values, such as the number of clusters *k*, to evaluate the impact of these parameter choices.\n",
    "\n",
    "Let's use inertia to help us validate our choice of *k*. To do so, we will create our own **elbow plot**, which looks at inertia against different values of *k*. Remember that the \"elbow\" of the plot indicates a good choice of *k*, where choosing any higher number of clusters only results in a marginal improvement in inertia. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8dec41",
   "metadata": {},
   "source": [
    "### *Task 10 - Evaluate k-means (run cells)*\n",
    "Run the four cells below to work through how we use inertia to evaluate k-means and select *k*.  \n",
    "\n",
    "First we will create a list of different values of *k* to inspect in our elbow plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c49ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of different values of k to test\n",
    "num_clusters = list(range(1,16))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23332c59",
   "metadata": {},
   "source": [
    "Next, for each of the 15 values of *k*, we will run the *k*-means algorithm again, compute the inertia, and store the score in a list.\n",
    "\n",
    "This is broken down in the `for` loop below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ca6ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list to store the inertia scores \n",
    "inertias = []\n",
    "\n",
    "# iterate over each value of k\n",
    "for i in num_clusters:\n",
    "    \n",
    "    # instantiate a model with the k number of clustesr\n",
    "    kmeans = KMeans(n_clusters=i, random_state=123)\n",
    "    \n",
    "    # fit the model to the scaled data\n",
    "    kmeans.fit_predict(data_scaled)\n",
    "    \n",
    "    # get the inertia score and append the value to the list\n",
    "    inertias.append(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444955e8",
   "metadata": {},
   "source": [
    "We can see we now have our list of 15 inertia scores, which we will then plot against our values for *k*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e007f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view all inertia scores\n",
    "inertias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf6fb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# elbow plot: plot inertia against k values\n",
    "# and look for the kink or \"elbow\" in the plot \n",
    "# to determine the optimal value of k\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "sns.lineplot(x=num_clusters, y=inertias)\n",
    "\n",
    "plt.xticks(num_clusters)\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"Inertia\")\n",
    "plt.title(\"Elbow test to find k\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0d41dc",
   "metadata": {},
   "source": [
    "We can see the elbow in the plot is located at k=3, meaning that there is not much decrease in inertia for each increase in the number of clusters beyond 3. Adding more clusters would simply add complexity without much improvement in performance. This helps validate our choice of *k*=3 earlier. \n",
    "\n",
    "### **Note: When do we use the elbow plot?**\n",
    "\n",
    "In this analysis, we first chose a number for *k*, and then we applied the elbow method to validate our choice. In practice, it is more helpful to perform the elbow method earlier in the analysis to first determine a potential choice of *k* before applying your algorithm and visualizing the results.\n",
    "\n",
    "Inertia is not the only metric we can use to evaluate our clusters. We will be exploring another internal metric, the **silhouette score**, later on in this module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8a1f84",
   "metadata": {},
   "source": [
    "## Interpret the results \n",
    "\n",
    "###  Explore the clusters\n",
    "\n",
    "The final part of the analysis involves taking a closer look at each of our clusters to see how the variables differ between them. This step is key to cluster analysis, since understanding what the groupings mean is up to the data analyst to determine, and not the computer. \n",
    "\n",
    "This requires a degree of domain knowledge and experimentation to find results that are useful and meaningful. \n",
    "\n",
    "### *Task 11 - inspect cluster membership*\n",
    "- Take a look at the countries within each of your final clusters. \n",
    "- *Hint:* One approach you might use is applying the `print()` function inside a `for` loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72963bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the countries within each cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0238189d",
   "metadata": {},
   "source": [
    "### Interpret the clusterings\n",
    "\n",
    "Now that we know which countries are in each of our clusters, an important final step to the analysis is interpreting the clusters and assigning meaning to our groupings. \n",
    "\n",
    "### *Task 12 - interpretation*\n",
    "With some research, or using previous knowledge, how can our clusters help inform our understanding of similarities and differences among countries?\n",
    "\n",
    "*Your answer here:*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406f83fe",
   "metadata": {},
   "source": [
    "You might find that, while these two variables give some insight into what countries are similar on the basis of economic development, public health, and gender equality, there are certainly a number of other features we might want to explore. Later on in the module, we will have the opportunity to look at how adding more features to our dataset and clustering on more variables can allow us a potentially richer understanding of our country clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022fae86",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcf9716",
   "metadata": {},
   "source": [
    "# Next steps\n",
    "When we move beyond clustering on 2 or 3 dimensions, it's more difficult to visualize. Although clustering is trickier in multiple dimensions, this is where the technique excels. We no longer rely on our intuitions as much, and we let the algorithms reveal answers using data. We'll gain experience in our workshop and online practice on how to approach clustering when it's no longer possible to visualize our data all at once."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
